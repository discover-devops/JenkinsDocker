What is your Job Profile?

What is your DevOps Experience?

Why you want to learn DevOps?


Draw io
===============
https://app.diagrams.net/
Install Draw io locally on your machine

--------------------------------------
google
discover devops github 

https://github.com/discover-devops/DevOps_Course
------------------------------------------------------
Install GItBash:
https://git-scm.com/downloads


18.61.232.88

Local Git $ git --version
git version 2.43.0
Local Git $


start a working area (see also: git help tutorial)
   clone     Clone a repository into a new directory
   init      Create an empty Git repository or reinitialize an existing one

work on the current change (see also: git help everyday)
   add       Add file contents to the index
   mv        Move or rename a file, a directory, or a symlink
   restore   Restore working tree files
   rm        Remove files from the working tree and from the index

examine the history and state (see also: git help revisions)
   bisect    Use binary search to find the commit that introduced a bug
   diff      Show changes between commits, commit and working tree, etc
   grep      Print lines matching a pattern
   log       Show commit logs
   show      Show various types of objects
   status    Show the working tree status

grow, mark and tweak your common history
   branch    List, create, or delete branches
   commit    Record changes to the repository
   merge     Join two or more development histories together
   rebase    Reapply commits on top of another base tip
   reset     Reset current HEAD to the specified state
   switch    Switch branches
   tag       Create, list, delete or verify a tag object signed with GPG

collaborate (see also: git help workflows)
   fetch     Download objects and refs from another repository
   pull      Fetch from and integrate with another repository or a local branch
   push      Update remote refs along with associated objects


-------------------------------------------

Git INstallation:
-------------------


To install Git on an Ubuntu EC2 instance on AWS, follow these steps:

Step 1: Connect to Your EC2 Instance
First, you need to connect to your EC2 instance using SSH. You can do this from your terminal (Linux or macOS) or using a tool like PuTTY (Windows).

For Linux or macOS:

ssh -i /path/to/your-key.pem ubuntu@your-ec2-public-ip


For Windows (using PuTTY):
- Convert your `.pem` key to `.ppk` using PuTTYgen.
- Use PuTTY to connect to `ubuntu@your-ec2-public-ip`.

 Step 2: Update the Package List
Once connected, update the package list to ensure that you get the latest version of the package:

sudo apt-get update


 Step 3: Install Git
Now, install Git using the following command:

sudo apt-get install git -y


 Step 4: Verify the Installation
To verify that Git has been installed successfully, check the version:

git --version


Local Git $ git --version
git version 2.43.0
Local Git $
================================================================

Configuring Git

git config --global user.name "devops"
git config --global user.email "devops@gmail.com"
git config --global core.editor "vi"
git config --list

/root/myGitProject



git + verb


git add

Step #: YOu have to initialize a directory

git init


Local Git $ git init
Initialized empty Git repository in /root/myGitProject/.git/
Local Git $


Local Git $ vi myapp.py
Local Git $
Local Git $
Local Git $ ls
myapp.py
Local Git $ pwd
/root/myGitProject
Local Git $ git status
On branch master

No commits yet

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        myapp.py

nothing added to commit but untracked files present (use "git add" to track)
Local Git $


Local Git $ git add myapp.py
Local Git $ git status
On branch master

No commits yet

Changes to be committed:
  (use "git rm --cached <file>..." to unstage)
        new file:   myapp.py

Local Git $


Local Git $ git commit -m "Added a new Python Code"
[master (root-commit) de714cd] Added a new Python Code
 1 file changed, 1 insertion(+)
 create mode 100644 myapp.py
Local Git $


Local Git $ git status
On branch master
nothing to commit, working tree clean
Local Git $


File ------> is under OS control not GIT control ----> Untracked area.

Ste#1: Move the from from UNtracked area to Stgged area
git add <>
 
Srep#2: Once the file is in stagged are, you have commit this chnage
git commit -m "Some messge"



Local Git $ git log
commit 37e26143c5ba4279222826a30f58152e4dad46bd (HEAD -> master)
Author: devops <devops@gmail.com>
Date:   Sun Aug 18 15:18:57 2024 +0000

     Added a new TXT file

commit de714cd6fbfdde9f273110f5a3c9f93f4255ecf1
Author: devops <devops@gmail.com>
Date:   Sun Aug 18 15:11:23 2024 +0000

    Added a new Python Code
Local Git $



Local Git $ cat myapp.py
This is my Python code
Local Git $ echo "This is my 2nd line of code" >> myapp.py
Local Git $
Local Git $
Local Git $ cat myapp.py
This is my Python code
This is my 2nd line of code
Local Git $ git status
On branch master
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        modified:   myapp.py

no changes added to commit (use "git add" and/or "git commit -a")
Local Git $

Local Git $ cat myapp.py
This is my Python code
Local Git $ echo "This is my 2nd line of code" >> myapp.py
Local Git $  cat myapp.py
This is my Python code
This is my 2nd line of code
Local Git $  git status
On branch master
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        modified:   myapp.py

no changes added to commit (use "git add" and/or "git commit -a")
Local Git $ git add myapp.py
Local Git $
Local Git $
Local Git $ git status
On branch master
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
        modified:   myapp.py

Local Git $ git commit -m "Added  a new line of code"
[master 8921902] Added  a new line of code
 1 file changed, 1 insertion(+)
Local Git $


If you want to revert back the chnages:
----------------------------------------------
git restore <file>  ----> You have just modified and not yet STAGGED
git restore --staged <file>  ---> YOu have modified and STAGED the file


.gitignore
-----------------

Local Git $ touch a.mov
Local Git $ ls
a.mov  myapp.py  myfile.txt
Local Git $ git status
On branch master
Untracked files:
  (use "git add <file>..." to include in what will be committed)
        a.mov

nothing added to commit but untracked files present (use "git add" to track)
Local Git $

Local Git $ git status
On branch master
Untracked files:
  (use "git add <file>..." to include in what will be committed)
        a.mov

nothing added to commit but untracked files present (use "git add" to track)
Local Git $ echo "a.mov" > .gitignore
Local Git $
Local Git $
Local Git $ cat .gitignore
a.mov
Local Git $


Local Git $ git status
On branch master
Untracked files:
  (use "git add <file>..." to include in what will be committed)
        a.mov

nothing added to commit but untracked files present (use "git add" to track)
Local Git $ echo "a.mov" > .gitignore
Local Git $
Local Git $
Local Git $ cat .gitignore
a.mov
Local Git $ git status
On branch master
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        modified:   .gitignore

no changes added to commit (use "git add" and/or "git commit -a")
Local Git $ git add .gitignore
Local Git $ git commit -m " Added file inside GITIGNORE "
[master d11d1ad]  Added file inside GITIGNORE
 1 file changed, 1 insertion(+)
Local Git $ git status
On branch master
nothing to commit, working tree clean
Local Git $


Must Watch:
https://www.youtube.com/watch?v=vjMZssWMweA



GIt Branching:
------------------------

Local Git $ git branch
* master
Local Git $ git branch br100
Local Git $ git branch
  br100
* master
Local Git $ ls
a.mov  b.mov  c.mov  d.mov  myapp.py  myfile.txt  x.mov  y.mov  z.mov
Local Git $ git checkout br100
Switched to branch 'br100'
Local Git $ ls
a.mov  b.mov  c.mov  d.mov  myapp.py  myfile.txt  x.mov  y.mov  z.mov
Local Git $



3d5d6ad  ------> COmmit ID of the Br100
3d5d6ad

Local Git $ git merge br100 master
Updating d55337b..3d5d6ad
Fast-forward
 file100 | 0
 1 file changed, 0 insertions(+), 0 deletions(-)
 create mode 100644 file100
Local Git $


======================================================

24th Aug 2024
-----------------

Recursive Merging in Git

Concept:
Recursive merging is Git’s default merge strategy when merging branches with a shared history. It’s called "recursive" because if a branch has multiple merge bases (common ancestors), Git recursively merges them. 

This method is particularly powerful when dealing with complex branch histories, as it can handle multiple merge bases by merging them first and then continuing with the main merge.



$ mkdir recursive-merge-demo
$ cd recursive-merge-demo
$ git init


Git $ git log
commit 9a2ac88c59555e7cde7c56a3bdfeae6f4df22078 (HEAD -> master)
Author: Discover DevOps <discover.devops@gmail.com>
Date:   Sat Aug 24 14:50:45 2024 +0000

    Initial commit on main branch
Git $


Git $ git log
commit 973dba3300c1b1be64b659fb6421d951f6532b0c (HEAD -> master)
Author: Discover DevOps <discover.devops@gmail.com>
Date:   Sat Aug 24 14:56:33 2024 +0000

    Add a different line in main branch

commit 9a2ac88c59555e7cde7c56a3bdfeae6f4df22078 (feature)
Author: Discover DevOps <discover.devops@gmail.com>
Date:   Sat Aug 24 14:50:45 2024 +0000

    Initial commit on main branch
Git $


F-2
Git $ git commit -m "Add a line in feature-2 branch"
[feature-2 a9de467] Add a line in feature-2 branch
 1 file changed, 1 insertion(+)
Git $


Master : a9de467a24a9d0
F2: e325a8d

Master : 4cfdd53

Git $ git merge feature-2
Merge made by the 'recursive' strategy.
 fature2.txt | 0
 1 file changed, 0 insertions(+), 0 deletions(-)
 create mode 100644 fature2.txt

 MASTE#1: a1909e7



echo "# 3423542345" >> README.md
git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/discover-devops/3423542345.git
git push -u origin main



git init
git add app.py
git commit -m "Added a pY code"

git remote add <Local_Name>  <path_of_remote>

git remote add orgin https://github.com/discover-devops/24thAug2024.git

Git $ git remote add orgin https://github.com/discover-devops/24thAug2024.git

Git $ git remote -v
orgin   https://github.com/discover-devops/24thAug2024.git (fetch)
orgin   https://github.com/discover-devops/24thAug2024.git (push)
Git $


Git $ git fetch orgin
remote: Enumerating objects: 3, done.
remote: Counting objects: 100% (3/3), done.
remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)
Unpacking objects: 100% (3/3), 873 bytes | 33.00 KiB/s, done.
From https://github.com/discover-devops/24thAug2024
 * [new branch]      main       -> orgin/main
Git $

Git $ git push -u origin main
Enumerating objects: 3, done.
Counting objects: 100% (3/3), done.
Writing objects: 100% (3/3), 209 bytes | 209.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
To https://github.com/discover-devops/3423542345.git
 * [new branch]      main -> main
branch 'main' set up to track 'origin/main'.
Git $

git clone 

Git $ git push
fatal: The current branch dev has no upstream branch.
To push the current branch and set the remote as upstream, use

    git push --set-upstream origin dev

To have this happen automatically for branches without a tracking
upstream, see 'push.autoSetupRemote' in 'git help config'.

Git $



6df42eb  -------> 
\_ Initial content
\_ Initial commit

Git $ git reset a3ab04a
Unstaged changes after reset:
M       file.txt
Git $

The git reset command is an essential tool for managing your commit history and modifying your repository's state. 

Use the --soft, --mixed, and --hard options depending on how you want to handle the changes in your working directory and staging area. 

Always be cautious, especially when using the --hard option, as it can lead to data loss if not used carefully


a0abce0 
      \_ file1.txt
                  \_Hello, World!


9273700 ---> file2.txt  ---> This is file 2

db2cb53  ----> file3.txt ---> This is file 3


9a5c6cd] This is revert message This reverts commit 

===============
25th Aug
Docker:

A container is a standard unit of software that packages up code and all its dependencies

# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update


OR

apt  install docker.io


Common Commands:
  run         Create and run a new container from an image
  exec        Execute a command in a running container
  ps          List containers
  build       Build an image from a Dockerfile
  pull        Download an image from a registry
  push        Upload an image to a registry
  images      List images
  login       Log in to a registry
  logout      Log out from a registry
  search      Search Docker Hub for images
  version     Show the Docker version information
  info        Display system-wide information




Commands:
  attach      Attach local standard input, output, and error streams to a running container
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  events      Get real time events from the server
  export      Export a container's filesystem as a tar archive
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Return low-level information on Docker objects
  kill        Kill one or more running containers
  load        Load an image from a tar archive or STDIN
  logs        Fetch the logs of a container
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  rmi         Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  wait        Block until one or more containers stop, then print their exit codes


docker + verb


----------

1: Created a Linux UBUNTU machine
2: Installed Docker on  it.
3: Docker  deamon is running

Docker $ docker --version
Docker version 24.0.7, build 24.0.7-0ubuntu4.1
Docker $


Docker $ docker -v
Docker version 24.0.7, build 24.0.7-0ubuntu4.1
Docker $

4: I'll Launch a conatiner

docker run -d nginx

docker ps


Docker $ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
Docker $


Docker $ docker run -d nginx
Unable to find image 'nginx:latest' locally
latest: Pulling from library/nginx
e4fff0779e6d: Pull complete
2a0cb278fd9f: Pull complete
7045d6c32ae2: Pull complete
03de31afb035: Pull complete
0f17be8dcff2: Pull complete
14b7e5e8f394: Pull complete
23fa5a7b99a6: Pull complete
Digest: sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add
Status: Downloaded newer image for nginx:latest
21d3336bf361b94db4a30aec61f9ae8689c163d76aa5d6857f681cafb7dcc502
Docker $


Docker $ docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES
21d3336bf361   nginx     "/docker-entrypoint.…"   17 seconds ago   Up 15 seconds   80/tcp    blissful_panini
Docker $

ps -aux -----> Linux COmmand to list down all the process

Duplicate $ ps -aux | grep -i nginx
root        2259  0.0  0.3  11404  7552 ?        Ss   15:31   0:00 nginx: master process nginx -g daemon off;
message+    2306  0.0  0.1  11868  3172 ?        S    15:31   0:00 nginx: worker process
message+    2307  0.0  0.1  11868  3044 ?        S    15:31   0:00 nginx: worker process
root        2411  0.0  0.1   6944  2176 pts/3    S+   15:36   0:00 grep --color=auto -i nginx
Duplicate $


Duplicate $ history
    1  PS1="Duplicate $ "
    2  clear
    3  docker ps
    4  ps -eaf
    5  clear
    6  ps -aux
    7  clear
    8  ps -aux | grep -i nginx
    9  kill -9 2259
   10  ps -aux | grep -i nginx
   11  docker ps
   12  docker stop 1c7bf3ebdbdc
   13  docker ps
   14  docker ps -a
   15  docker images
   16  docker rm 1c7bf3ebdbdc
   17  docker ps -a
   18  docker rm blissful_panini
   19  clear
   20  docker ps
   21  docker ps -a
   22  dcoker images
   23  docker images
   24  docker rmi nginx
   25  docker run -d nginx
   26  docker ps
   27  clear
   28  docker version
   29  docker info
   30  clear
   31  docker ps
   32  docker ps -a
   33  docker kill 07f26425a344
   34  docker ps
   35  docker ps -a
   36  docker start 07f26425a344
   37  clear
   38  docker ps
   39  docker exec -it 07f26425a344 bash
   40  ls
   41  history
Duplicate $


Docker $ history
    1  PS1="Docker $ "
    2  clear
    3  sudo apt-get update
    4  clear
    5  docker
    6  apt  install docker.io
    7  clear
    8  docker
    9  clear
   10  docker --version
   11  docker -v
   12  docker
   13  clear
   14  docker ps
   15  docker run -d nginx
   16  docker ps
   17  dcoker
   18  docker
   19  clear
   20  ps -ef
   21  ps -ef |grepm-i docker
   22  ps -ef |grep -i docker
   23  clear
   24  ps -aux |grep -i docker
   25  docker
   26  clear
   27  docker images
   28  docker run nginx
   29  history
Docker $


app.py  requirements.tx

FROM python:3.8-slim
WORKDIR /app
COPY . /app
RUN pip install --no-cache-dir -r requirements.txt
EXPOSE 5000
CMD ["python", "app.py"]



Docker $ docker build -t samplewebapp .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
            Install the buildx component to build images with BuildKit:
            https://docs.docker.com/go/buildx/

Sending build context to Docker daemon  4.096kB
Step 1/6 : FROM python:3.8-slim
3.8-slim: Pulling from library/python
e4fff0779e6d: Pull complete
4a5c74102edc: Pull complete
8d7f4eef7e05: Pull complete
120a794db9c9: Pull complete
188f8c4ef238: Pull complete
Digest: sha256:f8b4609a66cdaa133fa57e2ca8e2f03de2ebb44ffefb4c0b8b2de782aefca4a1
Status: Downloaded newer image for python:3.8-slim
 ---> e7fd04b8ffc7
Step 2/6 : WORKDIR /app
 ---> Running in 1d762fb70f36
Removing intermediate container 1d762fb70f36
 ---> 0770038b265a
Step 3/6 : COPY . /app
 ---> 18dc4da56125
Step 4/6 : RUN pip install --no-cache-dir -r requirements.txt
 ---> Running in 782ee72eeed5
Collecting Flask==2.0.1
  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.8/94.8 kB 5.7 MB/s eta 0:00:00
Collecting Werkzeug==2.0.1
  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 kB 28.0 MB/s eta 0:00:00
Collecting click>=7.1.2
  Downloading click-8.1.7-py3-none-any.whl (97 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 242.4 MB/s eta 0:00:00
Collecting itsdangerous>=2.0
  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)
Collecting Jinja2>=3.0
  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.3/133.3 kB 227.1 MB/s eta 0:00:00
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)
Installing collected packages: Werkzeug, MarkupSafe, itsdangerous, click, Jinja2, Flask
Successfully installed Flask-2.0.1 Jinja2-3.1.4 MarkupSafe-2.1.5 Werkzeug-2.0.1 click-8.1.7 itsdangerous-2.2.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv

[notice] A new release of pip is available: 23.0.1 -> 24.2
[notice] To update, run: pip install --upgrade pip
Removing intermediate container 782ee72eeed5
 ---> 552bf29dc041
Step 5/6 : EXPOSE 5000
 ---> Running in 72249960c4f3
Removing intermediate container 72249960c4f3
 ---> f3fc4daac9b6
Step 6/6 : CMD ["python", "app.py"]
 ---> Running in 923a7a23984b
Removing intermediate container 923a7a23984b
 ---> a44238ff06b8
Successfully built a44238ff06b8
Successfully tagged samplewebapp:latest
Docker $


=========================


docker build -t User_name/repo_name:tagname .


Docker $ docker build -t discoverdevops/myprodapp:myPyApp1 .
DEPRECATED: The legacy builder is deprecated and will be removed in a future release.
            Install the buildx component to build images with BuildKit:
            https://docs.docker.com/go/buildx/

Sending build context to Docker daemon  4.096kB
Step 1/7 : FROM python:3.9-slim
3.9-slim: Pulling from library/python
e4fff0779e6d: Pull complete
5be20a4ff277: Pull complete
48174a2f2dd9: Pull complete
0cb9f64d8db6: Pull complete
c9140ff79093: Pull complete
Digest: sha256:1e3437daae1d9cebce372794eacfac254dd108200e47c8b7f56a633ebd3e2a0a
Status: Downloaded newer image for python:3.9-slim
 ---> d8892906392f
Step 2/7 : WORKDIR /app
 ---> Running in 8f26c9c8520d
Removing intermediate container 8f26c9c8520d
 ---> d1b6aca57ca3
Step 3/7 : COPY . /app
 ---> 2844a5caa227
Step 4/7 : RUN pip install --no-cache-dir -r requirements.txt
 ---> Running in 769111dd29ee
Collecting Flask==2.0.3
  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.6/95.6 kB 1.2 MB/s eta 0:00:00
Collecting click>=7.1.2
  Downloading click-8.1.7-py3-none-any.whl (97 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 5.9 MB/s eta 0:00:00
Collecting itsdangerous>=2.0
  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)
Collecting Jinja2>=3.0
  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.3/133.3 kB 8.1 MB/s eta 0:00:00
Collecting Werkzeug>=2.0
  Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.6/227.6 kB 12.0 MB/s eta 0:00:00
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Installing collected packages: MarkupSafe, itsdangerous, click, Werkzeug, Jinja2, Flask
Successfully installed Flask-2.0.3 Jinja2-3.1.4 MarkupSafe-2.1.5 Werkzeug-3.0.4 click-8.1.7 itsdangerous-2.2.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv

[notice] A new release of pip is available: 23.0.1 -> 24.2
[notice] To update, run: pip install --upgrade pip
Removing intermediate container 769111dd29ee
 ---> 7b898be35a78
Step 5/7 : EXPOSE 5000
 ---> Running in 20c67ff27535
Removing intermediate container 20c67ff27535
 ---> 9a42a5410f9a
Step 6/7 : ENV NAME World
 ---> Running in a4d10e642777
Removing intermediate container a4d10e642777
 ---> 64f9ff217dc2
Step 7/7 : CMD ["python", "app.py"]
 ---> Running in 6ad1a74093c4
Removing intermediate container 6ad1a74093c4
 ---> c6038597ac9e
Successfully built c6038597ac9e
Successfully tagged discoverdevops/myprodapp:myPyApp1
Docker $



docker run -d -p 80:5000 --name mypyApp3 discoverdevops/myprodapp:myPyApp3

 10.5.0.5:80 ------Docker 0 -----> COnatiner ----> 5000

 ------------------

  388  docker ps
  389  docker images
  390  docker system prune --all
  391  clear
  392  docker images
  393  docker ps
  394  docker ps -a
  395  clear
  396  mkdir python-docker-app
  397  cd  python-docker-app
  398  clear
  399  vi app.py
  400  echo "Flask==2.0.3" > requirements.txt
  401  cat requirements.txt
  402  vi Dockerfile
  403  docker images
  404  docker build -t discoverdevops/myprodapp:myPyApp1 .
  405  clear
  406  cat Dockerfile
  407  docker images
  408  ls
  409  cat Dockerfile
  410  clear
  411  docker login
  412  docker images
  413  docker push discoverdevops/myprodapp:myPyApp1
  414  docker system prune -all
  415  docker system prune --all
  416  cleaer
  417  clear
  418  docker images
  419  dcoker run --name mypyApp discoverdevops/myprodapp:myPyApp1
  420  docker run --name mypyApp discoverdevops/myprodapp:myPyApp1
  421  docker ps
  422  vi requirements.txt
  423  docker build -t discoverdevops/myprodapp:myPyApp2 .
  424  clear
  425  docker images
  426  docker push discoverdevops/myprodapp:myPyApp2
  427  docker run --name mypyApp2 discoverdevops/myprodapp:myPyApp2
  428  vi requirements.txt
  429  docker build -t discoverdevops/myprodapp:myPyApp3 .
  430  docker push discoverdevops/myprodapp:myPyApp3
  431  clear
  432  docker ps -a
  433  docker run -d -p 80:5000 --name mypyApp3 discoverdevops/myprodapp:myPyApp3
  434  docker ps
  435  pwd
  436  cd ..
  437  mkdir myNodeApp
  438  cd myNodeApp/
  439  ls
  440  git colne https://github.com/discover-devops/my-node-app.git
  441  git clone https://github.com/discover-devops/my-node-app.git
  442  clear
  443  ls
  444  cd my-node-app
  445  ls
  446  rm Readme.md deployment.yaml
  447  ls
  448  cat package.json
  449  cd app
  450  ls
  451  cat server.js
  452  cd ..
  453  clear
  454  cat Dockerfile
  455  vi Dockerfile
  456  docker image
  457  clear
  458  ls
  459  docker images
  460  docker build -t discoverdevops/myprodapp:myNodeApp1 .
  461  clear
  462  docker images
  463  docker push discoverdevops/myprodapp:myNodeApp1
  464  docker run discoverdevops/myprodapp:myNodeApp1
  465  clear
  466  docker system prune --all
  467  clear
  468  ip addr show
  469  clear
  470  docker network ls
  471  docker inspect bridge
  472  ip addr show
  473  clear
  474  docker run -dit --name conA alpine
  475  docker ps
  476  ip addr show
  477  clear
  478  docker ps
  479  docker run -dit --name conB alpine
  480  docker ps
  481  ip addr show
  482  lear
  483  history |grep run
  484  ip addr show
  485  clear
  486  docker network ls
  487  docker ps
  488  docker network create --driver bridge my-net
  489  docker network ls
  490  ip addr show
  491  clear
  492  docker ps
  493  docker kill c3a02e3127eb 9abd3a315ffa
  494  ip addr show
  495  clear
  496  docker network ls
  497  docker inspect my-net
  498  clear
  499  docker run -dit --name conX --network my-net alpine ash
  500  docker ps
  501  docker run -dit --name conY --network my-net alpine ash
  502  docker ps
------------------------



# Dockerfile

FROM ubuntu:latest
EXPOSE 3000 3001 3002 3003 3004 3005 ... 3050
----------------------------------------------


98.70.32.180
98.70.33.214



Docker Swarm
---------------

Step 1: Install Docker on Both Nodes ---> Done

Step 2: Initialize Docker Swarm
One machine will make it as Docker Swarm MASTER
Install Docker SWAM here and initialize it

# On Node1
sudo docker swarm init --advertise-addr 10.5.0.5
>>>>>>>>>>>>>>>>>>>>

DockerNode_1 $ sudo docker swarm init --advertise-addr 10.5.0.5
Swarm initialized: current node (x1zelqa7do66bn8tpfz3tsa6c) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-1fbo1g98fo35cnvwixk62jgfpp7faeixrpt90ck0wongf69a66-6xzcdqyc0iks6q6p5ac2gigfc 10.5.0.5:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

DockerNode_1 $

<<<<<<<<<<<<<<<<<<<<<<<<<<<<

Step 3: Join the Second Node to the Swarm
# On Node2
sudo docker swarm join --token <SWARM_JOIN_TOKEN> <Node1_IP>:2377
docker swarm join --token SWMTKN-1-1fbo1g98fo35cnvwixk62jgfpp7faeixrpt90ck0wongf69a66-6xzcdqyc0iks6q6p5ac2gigfc 10.5.0.5:2377

>>>>>>>>>>>>>>>>>>>>>>>>
DockerNode_2 $docker swarm join --token SWMTKN-1-1fbo1g98fo35cnvwixk62jgfpp7faeixrpt90ck0wongf69a66-6xzcdqyc0iks6q6p5ac2gigfc 10.5.0.5:2377
This node joined a swarm as a worker.
<<<<<<<<<<<<<<<<<<<<<<<<<<

Step 4: Create an Overlay Network

# On Node1
sudo docker network create -d overlay my-overlay-net

Step 5: Deploy Services on the Swarm

# On Node1
sudo docker service create --name nginx1 --network my-overlay-net --replicas 1 nginx

Deploy a Service on Node2
# On Node1 (with constraint to run on Node2)
sudo docker service create --name nginx2 --network my-overlay-net --replicas 1 --constraint 'node.hostname == JenkinsMaster' nginx


What is Docker Compose?
Docker Compose is a tool that allows you to define and manage multi-container Docker applications. 
With Docker Compose, you can define your application’s services, networks, and volumes in a single YAML file called docker-compose.yml. 
This file describes how your containers should be built, networked, and deployed, making it easier to manage complex, multi-container Docker applications.

Step 1: Install Docker and Docker Compose

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Install Docker Compose
sudo apt-get install docker-compose -y


Create the Python Application

# app.py

from flask import Flask

app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, Docker Compose!'

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)

touch requirements.txt
Flask==2.0.1

Create a Dockerfile

# Dockerfile

# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Make port 5000 available to the world outside this container
EXPOSE 5000

# Define environment variable
ENV NAME World

# Run app.py when the container launches
CMD ["python", "app.py"]


docker-compose.yml

# docker-compose.yml

version: '3'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    environment:
      - FLASK_ENV=development


sudo docker-compose build
sudo docker-compose up

===========================================
7th Sep 2024

Kubernetes:
------------

\_  Automated Deployment and Scaling (Sclale-in ans Scale Out)

\_ Container Scheduling and Resource Allocation

\_  Self-Healing and Fault Tolerance

\_ Version Control and Rolling Updates

\_Service Discovery and Load Balancing

\_ Networking and Service Management

\_Storage Orchestration

\_Monitoring and Logging

===================
What is a Pod in Kubernetes?
A Pod is the most basic and smallest deployable unit in Kubernetes. It is a logical group that can contain one or more containers. Pods represent a single instance of a running process in a Kubernetes cluster, and they are designed to run closely related containers together, sharing the same network and storage.

In simpler terms, a Pod encapsulates application containers, their storage resources, a unique network IP, and options for how the containers should run.

==============================


Kubernetes objects are essential because they serve as the building blocks of Kubernetes, enabling users to manage and orchestrate applications at scale. 

By defining and using these objects, Kubernetes users can declare the desired state of their applications and let Kubernetes ensure that the system is always in sync with this state.

Declarative Approach
In the declarative approach, you specify the desired state of the Kubernetes object in a configuration file (usually YAML). Kubernetes then ensures the cluster matches the desired state as defined in the file.

Imperative Approach
The imperative approach involves directly issuing commands to the Kubernetes API server to create, update, or delete objects. It's faster and more straightforward but less maintainable than the declarative approach.


Key Kubernetes Objects:

Pods: The smallest deployable unit that can contain one or more containers.

Services: An abstraction that defines a logical set of Pods and a policy for accessing them.

Deployments: Provides declarative updates to Pods and ReplicaSets.

ReplicaSets: Ensures that a specified number of Pod replicas are running at any given time.

ConfigMaps: Stores configuration data in key-value pairs that can be used by Pods.

Secrets: Stores sensitive data like passwords or API keys.

PersistentVolumes (PVs) & PersistentVolumeClaims (PVCs): Manages storage in Kubernetes.

Namespaces: Provides a mechanism to divide cluster resources between multiple users.

Ingress: Manages external access to services, typically via HTTP/HTTPS.

--------------------------------------

Basic Commands (Beginner):
  create          Create a resource from a file or from stdin
  expose          Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service
  run             Run a particular image on the cluster
  set             Set specific features on objects

Basic Commands (Intermediate):
  explain         Get documentation for a resource
  get             Display one or many resources
  edit            Edit a resource on the server
  delete          Delete resources by file names, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout         Manage the rollout of a resource
  scale           Set a new size for a deployment, replica set, or replication controller
  autoscale       Auto-scale a deployment, replica set, stateful set, or replication controller

Cluster Management Commands:
  certificate     Modify certificate resources
  cluster-info    Display cluster information
  top             Display resource (CPU/memory) usage
  cordon          Mark node as unschedulable
  uncordon        Mark node as schedulable
  drain           Drain node in preparation for maintenance
  taint           Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe        Show details of a specific resource or group of resources
  logs            Print the logs for a container in a pod
  attach          Attach to a running container
  exec            Execute a command in a container
  port-forward    Forward one or more local ports to a pod
  proxy           Run a proxy to the Kubernetes API server
  cp              Copy files and directories to and from containers
  auth            Inspect authorization
  debug           Create debugging sessions for troubleshooting workloads and nodes
  events          List events

Advanced Commands:
  diff            Diff the live version against a would-be applied version
  apply           Apply a configuration to a resource by file name or stdin
  patch           Update fields of a resource
  replace         Replace a resource by file name or stdin
  wait            Experimental: Wait for a specific condition on one or many resources
  kustomize       Build a kustomization target from a directory or URL

Settings Commands:
  label           Update the labels on a resource
  annotate        Update the annotations on a resource
  completion      Output shell completion code for the specified shell (bash, zsh, fish, or powershell)

Subcommands provided by plugins:

Other Commands:
  api-resources   Print the supported API resources on the server
  api-versions    Print the supported API versions on the server, in the form of "group/version"
  config          Modify kubeconfig files
  plugin          Provides utilities for interacting with plugins
  version         Print the client and server version information

Usage:


$ kubectl get namespace
NAME              STATUS   AGE
default           Active   8m4s
kube-node-lease   Active   8m4s
kube-public       Active   8m4s
kube-system       Active   8m4s


apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx-container
    image: nginx:latest
    ports:
    - containerPort: 80


kumar@MiniKube:~/myK8sObjects$ ls
myNgginxPod.yaml
kumar@MiniKube:~/myK8sObjects$ kubectl apply -f myNgginxPod.yaml
pod/nginx-pod created
kumar@MiniKube:~/myK8sObjects$ kubectl  get pod
NAME        READY   STATUS    RESTARTS   AGE
nginx-pod   1/1     Running   0          14s
kumar@MiniKube:~/myK8sObjects$



vi myRS.yaml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
  labels:
    app: nginx
spec:
  replicas: 3  # Number of NGINX replicas
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx-container
        image: nginx:latest
        ports:
        - containerPort: 80


replicas: 3   ----> This is my DEsire state
And right now how  many pods are actually running ---> 3

DS == CS

========================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3  # Number of pod replicas
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21.6  # NGINX image version
        ports:
        - containerPort: 80


replica: 30 ----> 20 

3 --- >10
======================================

StrategyType:           RollingUpdate
RollingUpdateStrategy:  25% max unavailable, 
                        25% max surge

                        100 ---- 25  125 100 old and 25 will new


kubectl rollout status deployment/nginx-deployment
kubectl rollout history deployment/nginx-deployment
kubectl rollout history deployment/nginx-deployment --revision=2
kubectl rollout undo deployment/nginx-deployment
kubectl rollout undo deployment/nginx-deployment --to-revision=2


K8S $ cat nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3  # Number of pod replicas
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21.6  # NGINX image version
        ports:
        - containerPort: 80


>>>>>>>>>>>>>>>>>>>>>>>>>>>



K8S $ cat nginx-clusterip-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP  # Internal-only service

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

LABELS
selector


LABEL----> kind of sticker 
AWS Tag
========================================

14th Sep 
-----------

vi NGinxDeplyment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80


vi svc.yaml


apiVersion: v1
kind: Service
metadata:
  name: nginx-clusterip-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP

==================================


apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-clusterip-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
---
===================================================


apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30007  # You can specify a port in the range 30000-32767 or leave it empty for auto-assignment
  type: NodePort

======================================

Step 1: Create NGINX Deployment

nginx-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80

kubectl apply -f nginx-deployment.yaml

kubectl get pods


Step 2: Expose NGINX Using a LoadBalancer Service

apiVersion: v1
kind: Service
metadata:
  name: nginx-loadbalancer-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer

kubectl apply -f nginx-loadbalancer-service.yaml
kubectl get service nginx-loadbalancer-service

NAME                        TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)        AGE
nginx-loadbalancer-service   LoadBalancer   10.100.200.1     <pending>         80:32000/TCP   30s


kubectl delete service nginx-loadbalancer-service
kubectl delete deployment nginx-deployment



====================
21st Sep2024
Jenkins:
https://www.jenkins.io/doc/book/installing/
https://youtu.be/XuMrEDA8cAI

Prerequisites

Minimum hardware requirements:
256 MB of RAM
1 GB of drive space 


Step #0: Install JAVA
java -version
sudo apt update
sudo apt install openjdk-11-jre
java -version

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
echo $PATH




Step #2: By Default Jenkins Listen on PORT 8080

sudo wget -O /usr/share/keyrings/jenkins-keyring.asc https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key
echo "deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc]" https://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins

Step #3: Start jenkins
Start Jenkins
sudo systemctl start jenkins
sudo systemctl status jenkins
sudo systemctl enable jenkins


http://20.244.94.165:8080/


A Build Automation Tool is a software tool designed to automate the process of building.



(compiling, linking, packaging) applications. 

In the context of software development, building refers to taking source code and converting it into a deployable artifact (such as a binary or a package like a .jar, .exe, or a Docker image).

What is Maven?
Maven is a powerful build automation tool primarily used for Java projects but can also be used for other programming languages.

Dependency Management
Standardized Project Structure
Build Automation

=================================

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">

  <modelVersion>4.0.0</modelVersion>

  <groupId>com.example.maven-samples</groupId>
  <artifactId>single-module-project</artifactId>
  <packaging>jar</packaging>
  <version>1.0-SNAPSHOT</version>
  <name>A Single Maven Module</name>
  <description>Sample single module Maven project with a working, deployable site.</description>
  <url>http://www.example.com</url>

  <properties>
    <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
    <project.reporting.outputEncoding>utf-8</project.reporting.outputEncoding>
  </properties>

  <distributionManagement>
    <site>
      <id>site-server</id>
      <name>Test Project Site</name>
      <url>file:///tmp/single-module-site</url>
    </site>
  </distributionManagement>

  <build>
    <finalName>${project.artifactId}</finalName>

    <plugins>
      <plugin>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>2.3.2</version>
        <configuration>
          <source>1.6</source>
          <target>1.6</target>
        </configuration>
      </plugin>
      
      <plugin>  
            <!-- Build an executable JAR -->  
            <groupId>org.apache.maven.plugins</groupId>  
            <artifactId>maven-jar-plugin</artifactId>  
            <version>3.1.0</version>  
            <configuration>  
                <archive>  
                    <manifest>  
                        <mainClass>com.example.Greeter</mainClass>  
                    </manifest>  
                </archive>  
            </configuration>  
        </plugin> 

      <plugin>
        <artifactId>maven-release-plugin</artifactId>
        <version>2.2.1</version>
      </plugin>

      <plugin>
        <artifactId>maven-resources-plugin</artifactId>
        <version>2.5</version>
      </plugin>

      <plugin>
        <artifactId>maven-site-plugin</artifactId>
        <version>3.0</version>
        <configuration>
          <reportPlugins>
            <plugin>
              <artifactId>maven-checkstyle-plugin</artifactId>
              <version>2.8</version>
            </plugin>

            <plugin>
              <artifactId>maven-javadoc-plugin</artifactId>
              <version>2.8</version>
            </plugin>

            <plugin>
              <artifactId>maven-jxr-plugin</artifactId>
              <version>2.3</version>
            </plugin>

            <plugin>
              <artifactId>maven-pmd-plugin</artifactId>
              <version>2.6</version>
            </plugin>

            <plugin>
              <artifactId>maven-project-info-reports-plugin</artifactId>
              <version>2.4</version>
            </plugin>

            <plugin>
              <artifactId>maven-surefire-report-plugin</artifactId>
              <version>2.11</version>
            </plugin>

            <plugin>
              <groupId>org.codehaus.mojo</groupId>
              <artifactId>cobertura-maven-plugin</artifactId>
              <version>2.5.1</version>
            </plugin>

            <plugin>
              <groupId>org.codehaus.mojo</groupId>
              <artifactId>findbugs-maven-plugin</artifactId>
              <version>2.3.3</version>
            </plugin>

            <plugin>
              <groupId>org.codehaus.mojo</groupId>
              <artifactId>taglist-maven-plugin</artifactId>
              <version>2.4</version>
            </plugin>
          </reportPlugins>
        </configuration>
      </plugin>

      <plugin>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>2.11</version>
      </plugin>

      <plugin>
        <groupId>org.mortbay.jetty</groupId>
        <artifactId>jetty-maven-plugin</artifactId>
        <version>8.0.0.M1</version>
      </plugin>
    </plugins>
  </build>

  <dependencies>

    <dependency>
      <groupId>javax.servlet</groupId>
      <artifactId>servlet-api</artifactId>
      <version>2.5</version>
    </dependency>

    <dependency>
      <groupId>javax.servlet.jsp</groupId>
      <artifactId>jsp-api</artifactId>
      <version>2.2</version>
    </dependency>

    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit-dep</artifactId>
      <version>4.10</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>org.hamcrest</groupId>
      <artifactId>hamcrest-core</artifactId>
      <version>1.2.1</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>org.hamcrest</groupId>
      <artifactId>hamcrest-library</artifactId>
      <version>1.2.1</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>org.mockito</groupId>
      <artifactId>mockito-core</artifactId>
      <version>1.8.5</version>
      <scope>test</scope>
    </dependency>
  </dependencies>

  <scm>
    <connection>scm:git:git@github.com:gabrielf/maven-samples.git</connection>
    <developerConnection>scm:git:git@github.com:gabrielf/maven-samples.git</developerConnection>
    <tag>HEAD</tag>
    <url>http://github.com/gabrielf/maven-samples</url>
  </scm>

  <prerequisites>
    <maven>3.0.3</maven>
  </prerequisites>

</project>

=======================

4.186.59.62
http:<IP_Address>:8080

http://20.244.94.165:8080/github-webhook/
http:// Jenkins_Server_ip:8080/github-webhook/

20.244.94.165

------------------------------

TOmCat Lab:
----------------

1: Destnation Machine
1.1 Install Tomcat
1.2 Configure Tomcat

2: We will create Jenkins CI job
This hob will generate the pks the WAR file

3: We will take this WAR file as an input fort he
CD job, the CD job will run our app
using this WAR filve over the Tomcat server

---------------



Step #1: Install Tomcat
https://github.com/discover-devops/JenkinsMaven/blob/main/Tomcat_Installation.md

https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.95/bin/apache-tomcat-9.0.95.tar.gz

curl -O https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.95/bin/apache-tomcat-9.0.95.tar.gz


apache-tomcat-9.0.95.tar.gz


403 Access Denied

You are not authorized to view this page.

By default the Manager is only accessible from a browser running on the same machine as Tomcat. If you wish to modify this restriction, you'll need to edit the Manager's context.xml file.

If you have already configured the Manager application to allow access and you have used your browsers back button, used a saved book-mark or similar then you may have triggered the cross-site request forgery (CSRF) protection that has been enabled for the HTML interface of the Manager application. You will need to reset this protection by returning to the main Manager page. Once you return to this page, you will be able to continue using the Manager application's HTML interface normally. If you continue to see this access denied message, check that you have the necessary permissions to access this application.

If you have not changed any configuration files, please examine the file conf/tomcat-users.xml in your installation. That file must contain the credentials to let you use this webapp.

For example, to add the manager-gui role to a user named tomcat with a password of s3cret, add the following to the config file listed above.

<role rolename="manager-gui"/>
<user username="tomcat" password="s3cret" roles="manager-gui"/>

Note that for Tomcat 7 onwards, the roles required to use the manager application were changed from the single manager role to the following four roles. You will need to assign the role(s) required for the functionality you wish to access.

    manager-gui - allows access to the HTML GUI and the status pages
    manager-script - allows access to the text interface and the status pages
    manager-jmx - allows access to the JMX proxy and the status pages
    manager-status - allows access to the status pages only

The HTML interface is protected against CSRF but the text and JMX interfaces are not. To maintain the CSRF protection:

    Users with the manager-gui role should not be granted either the manager-script or manager-jmx roles.
    If the text or jmx interfaces are accessed through a browser (e.g. for testing since these interfaces are intended for tools not humans) then the browser must be closed afterwards to terminate the session.

For more information - please see the Manager App How-To. 

====================================

Jenkins Server_IP : 20.244.94.165
docker Server_IP : 4.186.59.62
JenkinsNew: 20.244.47.18

/opt/tomcat/webapps/host-manager/META-INF/context.xml
/opt/tomcat/webapps/manager/META-INF/context.xml


<role rolename="manager-gui"/>
<role rolename="manager-script"/>
<role rolename="manager-jmx"/>
<role rolename="manager-status"/>
<user username="admin" password="admin" roles="manager-gui, manager-script, manager-jmx, manager-status"/>
<user username="deployer" password="deployer" roles="manager-script"/>
<user username="tomcat" password="s3cret" roles="manager-gui"/>


**/*.war

http://4.186.59.62:8080

================================

LAB: creating a CI/CD pipeline using Jenkins and Docker 

#1: Jenkins installed and running--- Done
#2: Docker installed on the Jenkins server : apt-get install docker.io
#3: A public or private repository (GitHub).
#4: Docker Hub account (credentials for pushing images).
#5: A server or VM where Docker is installed for deployment.

Step 1: Set Up Jenkins Plugins
=====================================
 List of Plugins:
 \_ Docker Pipeline 
 \_ SSH Pipeline Steps 
 \_ Pipeline

 Step#2: 

 2.1: Create a Dockerfile

 # Dockerfile for NGINX
FROM nginx:alpine
COPY ./index.html /usr/share/nginx/html/index.html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]


2.2: Create the HTML file

index.html
<!DOCTYPE html>
<html>
<head>
  <title>Welcome</title>
</head>
<body>
  <h1>Hello from my Jenkins-Docker pipeline!</h1>
</body>
</html>


Step 3: Add Docker Hub Credentials in Jenkins

3.1: Go to Manage Jenkins → Manage Credentials → (global).
3.2: Click on Add Credentials.
3.3: Set the type to Username with password, and fill in your Docker Hub username and password.
3.4: Give it an ID (e.g., dockerhub-credentials), which you’ll use later in the pipeline.

Step 4: Create the CI Job (Build and Push Docker Image)



pipeline {
    agent any
    environment {
        DOCKER_HUB_CREDENTIALS = credentials('c5a41cbe-9b4b-45e3-b02a-52f6ab5d63fc') // Replace with your Jenkins credentials ID
    }
    stages {
        stage('Checkout Code') {
            steps {
                git branch: 'main', url: 'https://github.com/discover-devops/JenkinsDocker.git'  // Your public repo URL
            }
        }
        stage('Build Docker Image') {
            steps {
                script {
                    // Build Docker image from Dockerfile
                    def app = docker.build("discoverdevops/mywebapp")
                }
            }
        }
        stage('Push Docker Image to Docker Hub') {
            steps {
                script {
                    // Use Docker Hub credentials to log in and push the image
                    docker.withRegistry('https://index.docker.io/v1/', DOCKER_HUB_CREDENTIALS) {
                        def app = docker.build("discoverdevops/mywebapp")
                        app.push('latest')  // Push the image to Docker Hub with the 'latest' tag
                    }
                }
            }
        }
    }
}



discoverdevops/mywebapp

-----------------------------------

Terraform
29th Sep 2024


https://registry.terraform.io/providers/hashicorp/aws/latest
hashicorp/terraform-provider-aws 

Installation:
https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli



AWS Access Key ID [None]: xxxxx
AWS Secret Access Key [None]: xxxx
Default region name [None]: ap-south-1
Default output format [None]: text
MyTerraform $


sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform


Main commands:
  init          Prepare your working directory for other commands
  validate      Check whether the configuration is valid
  plan          Show changes required by the current configuration
  apply         Create or update infrastructure
  destroy       Destroy previously-created infrastructure


terrafrom + Verb

MyTerraform $ terraform --version
Terraform v1.9.6
on linux_amd64
MyTerraform $

---------------------------------

How Terraform works:

1: Take a sample CODE.
2: With that Code we will provision an EC2 instance
3: In this process, we will discover how terraform works?

---------------------

# Terraform Settings Block
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      #version = "~> 3.21" # Optional but recommended in production
    }
  }
}

# Provider Block
provider "aws" {
  profile = "default" # AWS Credentials Profile configured on your local desktop terminal  $HOME/.aws/credentials
  region  = "ap-south-1"
}

# Resource Block
resource "aws_instance" "ec2demo" {
  ami           = "ami-06f621d90fa29f6d0" # Amazon Linux in us-east-1, update as per your region
  instance_type = "t2.micro"
}

----------------------------------------------------------

MyTerraform $ terraform init
Initializing the backend...
Initializing provider plugins...
- Finding latest version of hashicorp/aws...
- Installing hashicorp/aws v5.69.0...
- Installed hashicorp/aws v5.69.0 (signed by HashiCorp)
Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.



terraform {
  backend "s3" {
    bucket = "mybucket"
    key    = "path/to/my/key"
    region = "us-east-1"
  }
}


terraform_project/
├── backend.tf
├── provider.tf
└── ec2-instance.tf


https://www.youtube.com/watch?v=uj7Ting6Ckk
AWS VPC dive depp --> re:invent
=================================================================


terraform_project/
├── terraform-provider.tf
└── ec2-instance.tf

Initialize the Configuration  ---------> terraform init
Plan the Configuration -------> terraform plan
Apply the Configuration  ----> terraform apply

aws_instance.ec2demo: Creating...
aws_instance.ec2demo: Still creating... [10s elapsed]
aws_instance.ec2demo: Creation complete after 13s [id=i-03db81a29492f0f3c]


------------------------------------

Create a VPC
------------------

1: Name 
2: CIDR
3: IGW ------> Attche with the VPC
4: Defautl route Table -------------------> COnnectivity with INTERNAL COmmuncation
5: Subnets
   \_ Public subnet  ---------> EC2 will comminate to INTERNET
                                RT ---- 0.0.0.0/0 IGW
                                Attch this RT with pulic subnet
                                enable public setting at Subnet level
                                SUBNET CIDR
                                Specify AZ
                                Attche this SUBNET
                                to the VPC we have created above in our code


   \_ Private subnet
                                RT ---- ONLY for internal COmm
                                Attch this RT with priavte subnet
                                SUBNET CIDR
                                Specify AZ
                                Attche this SUBNET
                                to the VPC we have created above in our code
---------------------------------------

mkdir terraform_project

cd  terraform_project

vi providers.tf

vi vpc.tf

resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name = "main-vpc"
  }
}

resource "aws_subnet" "public" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.1.0/24"
  map_public_ip_on_launch = true
  availability_zone = "ap-south-1a"
  tags = {
    Name = "public-subnet"
  }
}

resource "aws_subnet" "private" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.2.0/24"
  availability_zone = "ap-south-1a"
  tags = {
    Name = "private-subnet"
  }
}


resource "aws_internet_gateway" "gw" {
  vpc_id = aws_vpc.main.id
  tags = {
    Name = "main-gateway"
  }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.gw.id
  }

  tags = {
    Name = "public-route-table"
  }
}

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

resource "aws_route_table" "private" {
  vpc_id = aws_vpc.main.id
  tags = {
    Name = "private-route-table"
  }
}

resource "aws_route_table_association" "private" {
  subnet_id      = aws_subnet.private.id
  route_table_id = aws_route_table.private.id
}


outputs.tf

output "vpc_id" {
  description = "The ID of the VPC"
  value       = aws_vpc.main.id
}

output "public_subnet_id" {
  description = "The ID of the public subnet"
  value       = aws_subnet.public.id
}


output "private_subnet_id" {
  description = "The ID of the private subnet"
  value       = aws_subnet.private.id
}


---------------------------------------------------------


# security-group.tf

resource "aws_security_group" "web_sg" {
  vpc_id = aws_vpc.main.id
  description = "Allow HTTP and SSH traffic"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "web-sg"
  }
}

=================================

# ec2-instance.tf

resource "aws_instance" "web" {
  ami           = "ami-06f621d90fa29f6d0" # Update this as per your region
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.public.id  # Use the public subnet ID here
  vpc_security_group_ids = [aws_security_group.web_sg.id]  # Use the security group ID here

  user_data = <<-EOF
              #!/bin/bash
              yum update -y
              yum install -y httpd
              systemctl start httpd
              systemctl enable httpd
              echo "<html><h1>Hello from Terraform</h1></html>" > /var/www/html/index.html
              EOF

  tags = {
    Name = "web-server"
  }
}

-----------------------------

resource "aws_security_group" "example" {
  name = "example-sg"
}

resource "aws_instance" "example" {
  ami           = "ami-123456"
  instance_type = "t2.micro"
  
  # Implicit dependency: This instance depends on the security group.
  vpc_security_group_ids = [aws_security_group.example.id]
}


--------------------------

depends_on


resource "aws_s3_bucket" "example" {
  bucket = "my-bucket"
}

resource "aws_instance" "example" {
  ami           = "ami-123456"
  instance_type = "t2.micro"
  # Explicit dependency: Ensure the S3 bucket is created before the instance.
  depends_on = [aws_s3_bucket.example]
}
  

